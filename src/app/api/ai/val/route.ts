/**
 * Valle 360 - API da Val (Assistente de IA)
 * Responde perguntas e executa a√ß√µes usando GPT-4
 */

import { NextRequest, NextResponse } from 'next/server';
import { createRouteHandlerClient } from '@supabase/auth-helpers-nextjs';
import { cookies } from 'next/headers';
import { getOpenAIClient, OPENAI_MODELS } from '@/lib/integrations/openai/client';

export const dynamic = 'force-dynamic';

// Contexto do sistema para a Val
const VAL_SYSTEM_PROMPT = `Voc√™ √© a Val, assistente de IA da Valle 360 - uma plataforma de gest√£o para ag√™ncias de marketing digital.

Sua personalidade:
- Profissional mas amig√°vel
- Proativa em sugerir a√ß√µes
- Conhecedora profunda de marketing digital, gest√£o de ag√™ncias e neg√≥cios
- Sempre oferece solu√ß√µes pr√°ticas
- Usa emojis ocasionalmente para ser mais acolhedora

Suas capacidades:
- Responder perguntas sobre o neg√≥cio, clientes, finan√ßas, equipe
- Sugerir a√ß√µes baseadas em dados
- Ajudar com estrat√©gias de marketing
- Gerar insights e recomenda√ß√µes
- Auxiliar em tarefas do dia-a-dia

Contexto do Sistema Valle 360:
- Gerencia clientes de ag√™ncias de marketing
- Acompanha tarefas, projetos e equipes
- Monitora finan√ßas e contratos
- Analisa sentimento e NPS
- Integra com diversas ferramentas (Meta Ads, Google Ads, N8N, etc)

Ao responder:
1. Seja concisa mas completa
2. Se tiver dados dispon√≠veis, use-os na resposta
3. Sempre sugira pr√≥ximos passos quando relevante
4. Se n√£o souber algo, seja honesta
5. Ofere√ßa executar a√ß√µes quando poss√≠vel

Formato de resposta - SEMPRE retorne JSON:
{
  "message": "Sua resposta aqui",
  "suggestions": ["Sugest√£o 1", "Sugest√£o 2"],
  "actions": [
    {
      "label": "Texto do bot√£o",
      "action": "tipo_acao",
      "params": {}
    }
  ],
  "data": {} // Dados relevantes se houver
}`;

// POST - Conversar com a Val
export async function POST(request: NextRequest) {
  try {
    const cookieStore = cookies();
    const supabase = createRouteHandlerClient({ cookies: () => cookieStore });

    // Verificar autentica√ß√£o
    const { data: { user }, error: authError } = await supabase.auth.getUser();
    if (authError || !user) {
      return NextResponse.json({ error: 'N√£o autorizado' }, { status: 401 });
    }

    const body = await request.json();
    const { message, context, history } = body;

    if (!message) {
      return NextResponse.json({ error: 'Mensagem √© obrigat√≥ria' }, { status: 400 });
    }

    // Buscar dados relevantes para contexto
    const [profileData, clientsData, tasksData, alertsData] = await Promise.all([
      supabase.from('user_profiles').select('*').eq('id', user.id).single(),
      supabase.from('user_profiles').select('id, full_name, email').eq('user_type', 'cliente').limit(10),
      supabase.from('tasks').select('*').eq('status', 'pending').limit(5),
      supabase.from('sentiment_alerts').select('*').eq('status', 'pending').limit(5)
    ]);

    const businessContext = {
      currentUser: profileData.data?.full_name || user.email,
      userRole: profileData.data?.user_type || 'unknown',
      recentClients: clientsData.data?.map(c => c.full_name) || [],
      pendingTasks: tasksData.data?.length || 0,
      pendingAlerts: alertsData.data?.length || 0,
      currentDate: new Date().toLocaleDateString('pt-BR'),
      currentTime: new Date().toLocaleTimeString('pt-BR'),
      ...context
    };

    // Construir mensagens para o chat
    const messages: any[] = [
      { role: 'system', content: VAL_SYSTEM_PROMPT },
      { 
        role: 'system', 
        content: `Contexto atual do neg√≥cio:\n${JSON.stringify(businessContext, null, 2)}`
      }
    ];

    // Adicionar hist√≥rico se houver
    if (history && Array.isArray(history)) {
      history.slice(-10).forEach((msg: any) => {
        messages.push({
          role: msg.role === 'user' ? 'user' : 'assistant',
          content: typeof msg.content === 'string' ? msg.content : JSON.stringify(msg.content)
        });
      });
    }

    // Adicionar mensagem atual
    messages.push({ role: 'user', content: message });

    const client = getOpenAIClient();

    const response = await client.chat.completions.create({
      model: OPENAI_MODELS.chat,
      messages,
      temperature: 0.7,
      max_tokens: 1000,
      response_format: { type: 'json_object' }
    });

    const content = response.choices[0]?.message?.content;
    if (!content) {
      throw new Error('Resposta vazia da IA');
    }

    let parsedResponse;
    try {
      parsedResponse = JSON.parse(content);
    } catch {
      // Se n√£o for JSON v√°lido, criar estrutura padr√£o
      parsedResponse = {
        message: content,
        suggestions: [],
        actions: []
      };
    }

    // Registrar intera√ß√£o
    await supabase.from('val_interactions').insert({
      user_id: user.id,
      message: message,
      response: parsedResponse.message,
      context: businessContext
    }).catch(() => {}); // Ignorar erro se tabela n√£o existir

    return NextResponse.json({
      success: true,
      response: parsedResponse,
      timestamp: new Date().toISOString()
    });

  } catch (error: any) {
    console.error('Erro na API da Val:', error);
    return NextResponse.json({ 
      error: 'Erro ao processar mensagem',
      details: error.message 
    }, { status: 500 });
  }
}

// GET - Obter sugest√µes proativas da Val
export async function GET(request: NextRequest) {
  try {
    const cookieStore = cookies();
    const supabase = createRouteHandlerClient({ cookies: () => cookieStore });

    // Verificar autentica√ß√£o
    const { data: { user }, error: authError } = await supabase.auth.getUser();
    if (authError || !user) {
      return NextResponse.json({ error: 'N√£o autorizado' }, { status: 401 });
    }

    // Buscar dados para an√°lise
    const [alertsData, tasksData, paymentsData] = await Promise.all([
      supabase.from('sentiment_alerts').select('*').eq('status', 'pending').limit(3),
      supabase.from('tasks').select('*').eq('status', 'pending').order('due_date').limit(5),
      supabase.from('contracts').select('*').eq('status', 'pending_payment').limit(3)
    ]);

    const client = getOpenAIClient();

    const response = await client.chat.completions.create({
      model: OPENAI_MODELS.chat,
      messages: [
        { 
          role: 'system', 
          content: `Voc√™ √© a Val. Gere 2-3 sugest√µes proativas curtas baseadas nos dados.
Retorne JSON: { "suggestions": [{ "icon": "emoji", "text": "sugest√£o curta", "priority": "high/medium/low" }] }`
        },
        { 
          role: 'user', 
          content: JSON.stringify({
            pendingAlerts: alertsData.data?.length || 0,
            pendingTasks: tasksData.data?.length || 0,
            pendingPayments: paymentsData.data?.length || 0,
            currentTime: new Date().toLocaleTimeString('pt-BR')
          })
        }
      ],
      temperature: 0.8,
      max_tokens: 300,
      response_format: { type: 'json_object' }
    });

    const content = response.choices[0]?.message?.content;
    const parsed = content ? JSON.parse(content) : { suggestions: [] };

    return NextResponse.json({
      success: true,
      suggestions: parsed.suggestions || []
    });

  } catch (error: any) {
    console.error('Erro ao buscar sugest√µes:', error);
    return NextResponse.json({ 
      suggestions: [
        { icon: 'üëã', text: 'Ol√°! Como posso ajudar voc√™ hoje?', priority: 'low' }
      ]
    });
  }
}

